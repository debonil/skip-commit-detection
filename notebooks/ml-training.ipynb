{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load \n",
    "import pandas as pd\n",
    "import os, glob\n",
    "processed_files_path = 'processed_data'\n",
    "processed_files = glob.glob(os.path.join(processed_files_path , \"*.csv\"))\n",
    "\n",
    "\n",
    "li = []\n",
    "for filename in processed_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "commits_df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processed_data\\\\dropwizard_dropwizard.csv',\n",
       " 'processed_data\\\\eBay_parallec.csv',\n",
       " 'processed_data\\\\gradle_tooling-commons.csv',\n",
       " 'processed_data\\\\GrammarViz2_grammarviz2_src.csv',\n",
       " 'processed_data\\\\jMotif_GI.csv',\n",
       " 'processed_data\\\\jMotif_SAX.csv',\n",
       " 'processed_data\\\\ksclarke_solr-iso639-filter.csv',\n",
       " 'processed_data\\\\mtsar_mtsar.csv',\n",
       " 'processed_data\\\\steve-community_steve.csv',\n",
       " 'processed_data\\\\tracee_contextlogger.csv',\n",
       " 'processed_data\\\\zixpo_candybar.csv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11556, 76)\n"
     ]
    }
   ],
   "source": [
    "commits_df = commits_df.loc[:, (commits_df != 0).any(axis=0)].fillna(0.0)\n",
    "\n",
    "print(commits_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn\n",
    "#seaborn.pairplot(commits_df.drop('LABEL', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = commits_df.drop(['LABEL'], axis = 1)\n",
    "y = commits_df['LABEL']\n",
    "training, testing, training_labels, testing_labels = train_test_split(X, y, test_size = .25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Normalize the data\n",
    "sc = StandardScaler()\n",
    "normed_train_data = pd.DataFrame(sc.fit_transform(training), columns = X.columns)\n",
    "normed_test_data = pd.DataFrame(sc.fit_transform(testing), columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,f1_score,roc_auc_score,precision_score,recall_score,balanced_accuracy_score\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "    \"Logistic Regression\",\n",
    "    \"Ridge Classifier\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    GaussianProcessClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    MLPClassifier(hidden_layer_sizes=(100,100)),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression(),\n",
    "    RidgeClassifier(),\n",
    "    SVC(kernel=\"linear\",max_iter=100),\n",
    "    SVC(max_iter=100),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      2678\n",
      "           1       0.56      0.39      0.46       211\n",
      "\n",
      "    accuracy                           0.93      2889\n",
      "   macro avg       0.76      0.68      0.71      2889\n",
      "weighted avg       0.92      0.93      0.93      2889\n",
      "\n",
      "[[2614   64]\n",
      " [ 128   83]]\n",
      "GaussianProcessClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      2678\n",
      "           1       0.87      0.34      0.49       211\n",
      "\n",
      "    accuracy                           0.95      2889\n",
      "   macro avg       0.91      0.67      0.73      2889\n",
      "weighted avg       0.94      0.95      0.94      2889\n",
      "\n",
      "[[2667   11]\n",
      " [ 139   72]]\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90      2678\n",
      "           1       0.18      0.37      0.24       211\n",
      "\n",
      "    accuracy                           0.83      2889\n",
      "   macro avg       0.56      0.62      0.57      2889\n",
      "weighted avg       0.89      0.83      0.85      2889\n",
      "\n",
      "[[2315  363]\n",
      " [ 133   78]]\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      2678\n",
      "           1       0.87      0.35      0.49       211\n",
      "\n",
      "    accuracy                           0.95      2889\n",
      "   macro avg       0.91      0.67      0.73      2889\n",
      "weighted avg       0.94      0.95      0.94      2889\n",
      "\n",
      "[[2667   11]\n",
      " [ 138   73]]\n",
      "MLPClassifier(hidden_layer_sizes=(100, 100))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      2678\n",
      "           1       0.85      0.35      0.49       211\n",
      "\n",
      "    accuracy                           0.95      2889\n",
      "   macro avg       0.90      0.67      0.73      2889\n",
      "weighted avg       0.94      0.95      0.94      2889\n",
      "\n",
      "[[2665   13]\n",
      " [ 138   73]]\n",
      "AdaBoostClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      2678\n",
      "           1       0.72      0.26      0.38       211\n",
      "\n",
      "    accuracy                           0.94      2889\n",
      "   macro avg       0.83      0.63      0.68      2889\n",
      "weighted avg       0.93      0.94      0.93      2889\n",
      "\n",
      "[[2657   21]\n",
      " [ 156   55]]\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2678\n",
      "           1       0.00      0.00      0.00       211\n",
      "\n",
      "    accuracy                           0.93      2889\n",
      "   macro avg       0.46      0.50      0.48      2889\n",
      "weighted avg       0.86      0.93      0.89      2889\n",
      "\n",
      "[[2678    0]\n",
      " [ 211    0]]\n",
      "QuadraticDiscriminantAnalysis()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2678\n",
      "           1       0.00      0.00      0.00       211\n",
      "\n",
      "    accuracy                           0.93      2889\n",
      "   macro avg       0.46      0.50      0.48      2889\n",
      "weighted avg       0.86      0.93      0.89      2889\n",
      "\n",
      "[[2678    0]\n",
      " [ 211    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      2678\n",
      "           1       0.69      0.36      0.47       211\n",
      "\n",
      "    accuracy                           0.94      2889\n",
      "   macro avg       0.82      0.67      0.72      2889\n",
      "weighted avg       0.93      0.94      0.93      2889\n",
      "\n",
      "[[2645   33]\n",
      " [ 136   75]]\n",
      "RidgeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      2678\n",
      "           1       0.69      0.35      0.46       211\n",
      "\n",
      "    accuracy                           0.94      2889\n",
      "   macro avg       0.82      0.67      0.72      2889\n",
      "weighted avg       0.93      0.94      0.93      2889\n",
      "\n",
      "[[2644   34]\n",
      " [ 137   74]]\n",
      "SVC(kernel='linear', max_iter=100)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.07      0.13      2678\n",
      "           1       0.07      0.89      0.13       211\n",
      "\n",
      "    accuracy                           0.13      2889\n",
      "   macro avg       0.48      0.48      0.13      2889\n",
      "weighted avg       0.83      0.13      0.13      2889\n",
      "\n",
      "[[ 186 2492]\n",
      " [  24  187]]\n",
      "SVC(max_iter=100)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.35      0.51      2678\n",
      "           1       0.08      0.72      0.14       211\n",
      "\n",
      "    accuracy                           0.38      2889\n",
      "   macro avg       0.51      0.54      0.33      2889\n",
      "weighted avg       0.88      0.38      0.48      2889\n",
      "\n",
      "[[ 941 1737]\n",
      " [  59  152]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifiers_perf = []\n",
    "for clf in classifiers:\n",
    "    \n",
    "    clf.fit(normed_train_data, training_labels)\n",
    "    preds = clf.predict(normed_test_data)\n",
    "    \n",
    "    print(clf)\n",
    "    print(classification_report(testing_labels,preds))\n",
    "    print(confusion_matrix(testing_labels, preds))\n",
    "    classifiers_perf.append({\n",
    "        \"classifier\":clf,\n",
    "        \"accuracy_score\":accuracy_score(testing_labels,preds),\n",
    "        \"balanced_accuracy_score\":balanced_accuracy_score(testing_labels,preds),\n",
    "        \"f1_score\":f1_score(testing_labels,preds),\n",
    "        \"roc_auc_score\":roc_auc_score(testing_labels,preds),\n",
    "        \"precision_score\":precision_score(testing_labels,preds),\n",
    "        \"recall_score\":recall_score(testing_labels,preds),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier(n_neighbors=3)</td>\n",
       "      <td>0.933541</td>\n",
       "      <td>0.684733</td>\n",
       "      <td>0.463687</td>\n",
       "      <td>0.684733</td>\n",
       "      <td>0.564626</td>\n",
       "      <td>0.393365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianProcessClassifier()</td>\n",
       "      <td>0.948079</td>\n",
       "      <td>0.668562</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.668562</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.341232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.828314</td>\n",
       "      <td>0.617060</td>\n",
       "      <td>0.239264</td>\n",
       "      <td>0.617060</td>\n",
       "      <td>0.176871</td>\n",
       "      <td>0.369668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.948425</td>\n",
       "      <td>0.670932</td>\n",
       "      <td>0.494915</td>\n",
       "      <td>0.670932</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.345972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(100, 100))</td>\n",
       "      <td>0.947733</td>\n",
       "      <td>0.670559</td>\n",
       "      <td>0.491582</td>\n",
       "      <td>0.670559</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.345972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "      <td>0.938733</td>\n",
       "      <td>0.626411</td>\n",
       "      <td>0.383275</td>\n",
       "      <td>0.626411</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.260664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.926964</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QuadraticDiscriminantAnalysis()</td>\n",
       "      <td>0.926964</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.941502</td>\n",
       "      <td>0.671564</td>\n",
       "      <td>0.470219</td>\n",
       "      <td>0.671564</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.355450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RidgeClassifier()</td>\n",
       "      <td>0.940810</td>\n",
       "      <td>0.669007</td>\n",
       "      <td>0.463950</td>\n",
       "      <td>0.669007</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.350711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC(kernel='linear', max_iter=100)</td>\n",
       "      <td>0.129110</td>\n",
       "      <td>0.477855</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.477855</td>\n",
       "      <td>0.069802</td>\n",
       "      <td>0.886256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC(max_iter=100)</td>\n",
       "      <td>0.378332</td>\n",
       "      <td>0.535880</td>\n",
       "      <td>0.144762</td>\n",
       "      <td>0.535880</td>\n",
       "      <td>0.080466</td>\n",
       "      <td>0.720379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           classifier  accuracy_score  \\\n",
       "0                 KNeighborsClassifier(n_neighbors=3)        0.933541   \n",
       "1                         GaussianProcessClassifier()        0.948079   \n",
       "2                            DecisionTreeClassifier()        0.828314   \n",
       "3   (DecisionTreeClassifier(max_features='sqrt', r...        0.948425   \n",
       "4        MLPClassifier(hidden_layer_sizes=(100, 100))        0.947733   \n",
       "5   (DecisionTreeClassifier(max_depth=1, random_st...        0.938733   \n",
       "6                                        GaussianNB()        0.926964   \n",
       "7                     QuadraticDiscriminantAnalysis()        0.926964   \n",
       "8                                LogisticRegression()        0.941502   \n",
       "9                                   RidgeClassifier()        0.940810   \n",
       "10                 SVC(kernel='linear', max_iter=100)        0.129110   \n",
       "11                                  SVC(max_iter=100)        0.378332   \n",
       "\n",
       "    balanced_accuracy_score  f1_score  roc_auc_score  precision_score  \\\n",
       "0                  0.684733  0.463687       0.684733         0.564626   \n",
       "1                  0.668562  0.489796       0.668562         0.867470   \n",
       "2                  0.617060  0.239264       0.617060         0.176871   \n",
       "3                  0.670932  0.494915       0.670932         0.869048   \n",
       "4                  0.670559  0.491582       0.670559         0.848837   \n",
       "5                  0.626411  0.383275       0.626411         0.723684   \n",
       "6                  0.500000  0.000000       0.500000         0.000000   \n",
       "7                  0.500000  0.000000       0.500000         0.000000   \n",
       "8                  0.671564  0.470219       0.671564         0.694444   \n",
       "9                  0.669007  0.463950       0.669007         0.685185   \n",
       "10                 0.477855  0.129412       0.477855         0.069802   \n",
       "11                 0.535880  0.144762       0.535880         0.080466   \n",
       "\n",
       "    recall_score  \n",
       "0       0.393365  \n",
       "1       0.341232  \n",
       "2       0.369668  \n",
       "3       0.345972  \n",
       "4       0.345972  \n",
       "5       0.260664  \n",
       "6       0.000000  \n",
       "7       0.000000  \n",
       "8       0.355450  \n",
       "9       0.350711  \n",
       "10      0.886256  \n",
       "11      0.720379  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classifiers_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(training, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "print(clf.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696550132687204\n",
      "0.9425406715126341\n"
     ]
    }
   ],
   "source": [
    "print (clf.score(training, training_labels))\n",
    "print(clf.score(testing, testing_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9425406715126341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      2678\n",
      "           1       0.71      0.36      0.47       211\n",
      "\n",
      "    accuracy                           0.94      2889\n",
      "   macro avg       0.83      0.67      0.72      2889\n",
      "weighted avg       0.93      0.94      0.93      2889\n",
      "\n",
      "[[2648   30]\n",
      " [ 136   75]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "print(accuracy_score(testing_labels,preds))\n",
    "print(classification_report(testing_labels,preds))\n",
    "print(confusion_matrix(testing_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SIZE_LA</th>\n",
       "      <td>0.172635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM_readme</th>\n",
       "      <td>0.113063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIZE_LD</th>\n",
       "      <td>0.112086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIFF_ND</th>\n",
       "      <td>0.071394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM_update</th>\n",
       "      <td>0.060201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIFF_EN</th>\n",
       "      <td>0.059356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM_script</th>\n",
       "      <td>0.039796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM_updating</th>\n",
       "      <td>0.037406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM_release</th>\n",
       "      <td>0.035114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIFF_NF</th>\n",
       "      <td>0.033146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "SIZE_LA      0.172635\n",
       "CM_readme    0.113063\n",
       "SIZE_LD      0.112086\n",
       "DIFF_ND      0.071394\n",
       "CM_update    0.060201\n",
       "DIFF_EN      0.059356\n",
       "CM_script    0.039796\n",
       "CM_updating  0.037406\n",
       "CM_release   0.035114\n",
       "DIFF_NF      0.033146"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.feature_importances_, index=training.columns).sort_values(by=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ae7141c631147330982ab03a122191846cf83f5ea8efac7ef9984176873ce7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
